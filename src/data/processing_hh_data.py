# -*- coding: utf-8 -*-
"""processing_hh_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UXkXWaCbkpO0-xTrowb-xjQMiBduGM6E
"""

import pandas as pd
import gdown
import ast
import json
import numpy as np
import requests
from datetime import datetime
import nltk
nltk.download('punkt')
nltk.download('stopwords')
from collections import Counter
!pip install pymorphy2
import pymorphy2
from scipy import stats

# Загружаем таблицу с гугл-диска
url = '1OxQupfqEt36O2GwnP7gL-2Kq9pdR5Eii'
output = "vacancies.xlsx"
gdown.download('https://drive.google.com/uc?export=download&id=' + url, output, quiet=False)

df = pd.read_excel("vacancies.xlsx")

# Удаляем пустые или полностью одинаковые столбцы
for col in df.columns:
  if (sum(1-df[col].isnull()) == 0) or (sum(1 - (df[col] == str(df[col][0])))==0):
    del df[col]

# Переводим текст в словари в каждом столбце
python_code = []
for col in df.columns:
  try:
    df[col] = df[col].apply(lambda x: ast.literal_eval(x) if not pd.isnull(x) else None)
    python_code.append(col)
  except:
    pass

# Переводим текст в формат даты
df['created_at'] = df['created_at'].apply(lambda x: datetime.strptime(x,  "%Y-%m-%dT%H:%M:%S%z"))

df['created_at'] = df['created_at'].apply(lambda x: pd.to_datetime(x).date())

def func(x, key):
  output = []
  if x != []:
    for i in range(len(x)):
      output.append(x[i][key])
  return output

# Разбиваем словари и списки по столбцам
for col in python_code:
  i = 0
  while df[col][i] is None or df[col][i] == []:
    i += 1
  if col == 'employer':
    i = 1966
  try:
    for key in df[col][i].keys():
      if key != 'url' and key != 'alternate_url':
        df[f'{col}_{key}'] = df[col].apply(lambda x: x[key] if x is not None else None)
  except:
    for key in df[col][i][0].keys():
      if key != 'url' and key != 'alternate_url':
        df[f'{col}_{key}'] = df[col].apply(lambda x: func(x, key) if x != [] else None)
  df = df.drop(col, 1)

# Удаляем пустые или полностью одинаковые столбцы после разбиения
for col in df.columns:
  if (sum(1-df[col].isnull()) == 0) or (sum(1 - (df[col] == str(df[col][0])))==0):
    del df[col]

# Разбиваем словари и списки по столбцам, где были вложенные словари
for col in df.columns:
  i = 0
  while df[col][i] is None or df[col][i] == []:
    i += 1
  if type(df[col][i]) == dict:
    for key in df[col][i].keys():
      if key != 'url' and key != 'alternate_url':
        df[f'{col}_{key}'] = df[col].apply(lambda x: x[key] if x is not None else None)
    df = df.drop(col, 1)
  elif type(df[col][i]) == list:
    try:
      for key in df[col][i][0].keys():
        if key != 'url' and key != 'alternate_url':
          df[f'{col}_{key}'] = df[col].apply(lambda x: func(x, key) if (x != [] and x is not None) else None)
      df = df.drop(col, 1)
    except:
      pass

# Столбцы, которые можно удалить -- список (нужно?) пополнить
cols_to_remove = ["branded_description", "response_url", "apply_alternate_url", "alternate_url", "published_at", "immediate_redirect_url"]

# Удаляем столбцы из списка cols_to_remove
for col in cols_to_remove:
  del df[col]

# Избавляемся от html-кода в столбце 'description'
code = ['<li>', '</li>', '<strong>', '</strong>','<p>', '</p>','<ul>', '</ul>','&quot', '<em>', '<br />']
for word in code:
  df['description'] = df['description'].str.replace(word, '')

df.to_csv('vacancies.csv', index=False)